{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toxic Comments Classification\n",
    "### ML First Iteration_ Assignment 1\n",
    "\n",
    "#### The following notebook documents the first iteration on the toxic comments dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all imports and magic commands\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from my_measures import BinaryClassificationPerformance\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "#added countvectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class BinaryClassificationPerformance in module my_measures:\n",
      "\n",
      "class BinaryClassificationPerformance(builtins.object)\n",
      " |  BinaryClassificationPerformance(predictions, labels, desc, probabilities=None)\n",
      " |  \n",
      " |  Performance measures to evaluate the fit of a binary classification model, v1.02\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, predictions, labels, desc, probabilities=None)\n",
      " |      Initialize attributes: predictions-vector of predicted values for Y, labels-vector of labels for Y\n",
      " |  \n",
      " |  compute_measures(self)\n",
      " |      Compute performance measures defined by Flach p. 57\n",
      " |  \n",
      " |  img_indices(self)\n",
      " |      Get the indices of true and false positives to be able to locate the corresponding images in a list of image names\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(BinaryClassificationPerformance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for feature building and extraction on Natural Language data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that takes raw data and completes all preprocessing required before model fits\n",
    "def process_raw_data(fn, my_random_seed, test=False):\n",
    "    # read and summarize data\n",
    "    toxic_data = pd.read_csv(fn)\n",
    "    if (not test):\n",
    "        # add an indicator for any toxic, severe toxic, obscene, threat, insult, or indentity hate\n",
    "        toxic_data['any_toxic'] = (toxic_data['toxic'] + toxic_data['severe_toxic'] + toxic_data['obscene'] + toxic_data['threat'] + toxic_data['insult'] + toxic_data['identity_hate'] > 0)\n",
    "    print(\"toxic_data is:\", type(toxic_data))\n",
    "    print(\"toxic_data has\", toxic_data.shape[0], \"rows and\", toxic_data.shape[1], \"columns\", \"\\n\")\n",
    "    print(\"the data types for each of the columns in toxic_data:\")\n",
    "    print(toxic_data.dtypes, \"\\n\")\n",
    "    print(\"the first 10 rows in toxic_data:\")\n",
    "    print(toxic_data.head(5))\n",
    "    if (not test):\n",
    "        print(\"The rate of 'toxic' Wikipedia comments in the dataset: \")\n",
    "        print(toxic_data['any_toxic'].mean())\n",
    "\n",
    "    # vectorize Bag of Words from review text; as sparse matrix\n",
    "    if (not test): # fit_transform()\n",
    "        hv = HashingVectorizer(n_features=2 ** 15, alternate_sign=False)\n",
    "        X_hv = hv.fit_transform(toxic_data.comment_text)\n",
    "        fitted_transformations.append(hv) #what is this doing?\n",
    "        print(\"Shape of HashingVectorizer X:\")    \n",
    "        print(X_hv.shape)\n",
    "    else: # transform() \n",
    "        X_hv = fitted_transformations[0].transform(toxic_data.comment_text)\n",
    "        print(\"Shape of HashingVectorizer X:\")\n",
    "        print(X_hv.shape)\n",
    "    \n",
    "    # http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html\n",
    "    if (not test):\n",
    "        transformer = TfidfTransformer()\n",
    "        X_tfidf = transformer.fit_transform(X_hv)\n",
    "        fitted_transformations.append(transformer)\n",
    "    else:\n",
    "        X_tfidf = fitted_transformations[1].transform(X_hv)\n",
    "    \n",
    "    # create additional quantitative features\n",
    "    # features from Amazon.csv to add to feature set\n",
    "    toxic_data['word_count'] = toxic_data['comment_text'].str.split(' ').str.len()\n",
    "    toxic_data['punc_count'] = toxic_data['comment_text'].str.count(\"\\!\")\n",
    "    # should it be a boolean value? As str.find returns an index; how will a boolean be converted to 0 or 1\n",
    "    toxic_data['occur_fuck'] =(toxic_data['comment_text'].str.lower().str.count(\"fuck\"))\n",
    "    # toxic_data['occur_cock'] =(toxic_data['comment_text'].str.lower().str.count(\"cock\"))\n",
    "    #toxic_data['occur_shit'] =(toxic_data['comment_text'].str.lower().str.count(\"shit\"))\n",
    "    toxic_data['uppercase_letters'] = toxic_data['comment_text'].str.count(r'[A-Z]')\n",
    "    \n",
    "\n",
    "    X_quant_features = toxic_data[[ \"word_count\",\"occur_fuck\", \"punc_count\", \"uppercase_letters\"]]\n",
    "    print(\"Look at a few rows of the new quantitative features: \")\n",
    "    print(X_quant_features.head(10))\n",
    "    \n",
    "    # Combine all quantitative features into a single sparse matrix\n",
    "    X_quant_features_csr = csr_matrix(X_quant_features)\n",
    "    X_combined = hstack([X_tfidf, X_quant_features_csr])\n",
    "    X_matrix = csr_matrix(X_combined) # convert to sparse matrix\n",
    "    print(\"Size of combined bag of words and new quantitative variables matrix:\")\n",
    "    print(X_matrix.shape)\n",
    "    \n",
    "    # Create `X`, scaled matrix of features\n",
    "    # feature scaling\n",
    "    if (not test):\n",
    "        sc = StandardScaler(with_mean=False)\n",
    "        X = sc.fit_transform(X_matrix)\n",
    "        fitted_transformations.append(sc)\n",
    "        print(X.shape)\n",
    "        y = toxic_data['any_toxic']\n",
    "    else:\n",
    "        X = fitted_transformations[2].transform(X_matrix)\n",
    "        print(X.shape)\n",
    "    \n",
    "    # Create Training and Test Sets\n",
    "    # enter an integer for the random_state parameter; any integer will work\n",
    "    if (test):\n",
    "        X_submission_test = X\n",
    "        print(\"Shape of X_test for submission:\")\n",
    "        print(X_submission_test.shape)\n",
    "        print('SUCCESS!')\n",
    "        return(toxic_data, X_submission_test)\n",
    "    else: \n",
    "        X_train, X_test, y_train, y_test, X_raw_train, X_raw_test = train_test_split(X, y, toxic_data, test_size=0.2, random_state=my_random_seed)\n",
    "        print(\"Shape of X_train and X_test:\")\n",
    "        print(X_train.shape)\n",
    "        print(X_test.shape)\n",
    "        print(\"Shape of y_train and y_test:\")\n",
    "        print(y_train.shape)\n",
    "        print(y_test.shape)\n",
    "        print(\"Shape of X_raw_train and X_raw_test:\")\n",
    "        print(X_raw_train.shape)\n",
    "        print(X_raw_test.shape)\n",
    "        print('SUCCESS!')\n",
    "        return(X_train, X_test, y_train, y_test, X_raw_train, X_raw_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic_data is: <class 'pandas.core.frame.DataFrame'>\n",
      "toxic_data has 159571 rows and 9 columns \n",
      "\n",
      "the data types for each of the columns in toxic_data:\n",
      "id               object\n",
      "comment_text     object\n",
      "toxic             int64\n",
      "severe_toxic      int64\n",
      "obscene           int64\n",
      "threat            int64\n",
      "insult            int64\n",
      "identity_hate     int64\n",
      "any_toxic          bool\n",
      "dtype: object \n",
      "\n",
      "the first 10 rows in toxic_data:\n",
      "                 id                                       comment_text  toxic  \\\n",
      "0  0000997932d777bf  Explanation\\r\\nWhy the edits made under my use...      0   \n",
      "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
      "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
      "3  0001b41b1c6bb37e  \"\\r\\nMore\\r\\nI can't make any real suggestions...      0   \n",
      "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
      "\n",
      "   severe_toxic  obscene  threat  insult  identity_hate  any_toxic  \n",
      "0             0        0       0       0              0      False  \n",
      "1             0        0       0       0              0      False  \n",
      "2             0        0       0       0              0      False  \n",
      "3             0        0       0       0              0      False  \n",
      "4             0        0       0       0              0      False  \n",
      "The rate of 'toxic' Wikipedia comments in the dataset: \n",
      "0.10167887648758234\n",
      "Shape of HashingVectorizer X:\n",
      "(159571, 32768)\n",
      "Look at a few rows of the new quantitative features: \n",
      "   word_count  occur_fuck  punc_count  uppercase_letters\n",
      "0          42           0           0                 17\n",
      "1          18           0           1                  8\n",
      "2          42           0           0                  4\n",
      "3         112           0           0                 11\n",
      "4          13           0           0                  2\n",
      "5          12           0           0                  1\n",
      "6           8           0           0                 37\n",
      "7          21           0           0                  4\n",
      "8          83           0           0                  7\n",
      "9          12           0           0                  2\n",
      "Size of combined bag of words and new quantitative variables matrix:\n",
      "(159571, 32772)\n",
      "(159571, 32772)\n",
      "Shape of X_train and X_test:\n",
      "(127656, 32772)\n",
      "(31915, 32772)\n",
      "Shape of y_train and y_test:\n",
      "(127656,)\n",
      "(31915,)\n",
      "Shape of X_raw_train and X_raw_test:\n",
      "(127656, 13)\n",
      "(31915, 13)\n",
      "SUCCESS!\n",
      "Number of fits stored in `fitted_transformations` list: \n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# create an empty list to store any use of fit_transform() to transform() later\n",
    "# it is a global list to store model and feature extraction fits\n",
    "fitted_transformations = []\n",
    "\n",
    "X_train, X_test, y_train, y_test, X_raw_train, X_raw_test = process_raw_data(fn='toxiccomments_train.csv', my_random_seed=56)\n",
    "\n",
    "print(\"Number of fits stored in `fitted_transformations` list: \")\n",
    "print(len(fitted_transformations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model : SVM, Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 12926, 'Neg': 114730, 'TP': 11871, 'TN': 114251, 'FP': 479, 'FN': 1055, 'Accuracy': 0.9879833301999122, 'Precision': 0.9612145748987855, 'Recall': 0.9183815565526845, 'desc': 'svm_train'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "svm = linear_model.SGDClassifier(max_iter=2000, alpha=0.012)\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "svm_performance_train = BinaryClassificationPerformance(svm.predict(X_train), y_train, 'svm_train')\n",
    "svm_performance_train.compute_measures()\n",
    "print(svm_performance_train.performance_measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at some false positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_predictions = svm.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples of false positives:\n",
      "7927\n",
      "So it's not German? Than what the hell spelling is it?! You make no damn sense!\n",
      "* * * * * * * * * \n",
      "8529\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "OH LAWDY.\n",
      "O\n",
      "* * * * * * * * * \n",
      "9722\n",
      "in life because you're an admin, whoopee\n",
      "* * * * * * * * * \n",
      "14687\n",
      "Thank you for all the fun crap and allowing them to do what ever they want to\n",
      "\n",
      "Hope your happy they win there right im not\n",
      "* * * * * * * * * \n",
      "18318\n",
      "Edit: I see some can't let go of their old communist habits. You dare delete my messages in a talk page. 1- How is it not relevant when it is only a reply to your own bloody message. 2- Who are you to decide what's relevant? 3- Who are you decide what's relevant, decide the verdict and execute it? Shameless as always, as would be expected.\n",
      "* * * * * * * * * \n",
      "24464\n",
      "You want sources, there I added them.  Is that good enough for chrissakes?\n",
      "* * * * * * * * * \n",
      "28702\n",
      "'I am nobodies sock-puppet. this is tripe.\n",
      "* * * * * * * * * \n",
      "32294\n",
      "You mean my past BLOCK. The third block was because of your incompetence. Jesus doesn't like liars.\n",
      "* * * * * * * * * \n",
      "32762\n",
      "One question to the admins: If you intend to let the greek nazi propaganda pusher editors shape the article with NO evidence, isn't it better to use a forum to read this greek nazi crap instead of Greekopedia, at leat there they dont have to pretend to be objective.\n",
      "* * * * * * * * * \n",
      "44536\n",
      "Associação Académica de Coimbra 2\n",
      "One user did it all wrong after has read your requests and surveys. It's a shame that someone is trying to ruin the work of others just to promote his own stupid, ignorant or biased view about one topic. I know you didn't agree with his actions. I know it isn't your fault but it really pissed me off. I hope someone would be able to revert all the mess he did.\n",
      "* * * * * * * * * \n",
      "52832\n",
      "its a shame this guy keeps on using excuses!\n",
      "* * * * * * * * * \n",
      "55194\n",
      "Sorry \n",
      "\n",
      "Sorry man (Omicronpersei8) I just got a bit angry. And the original person I attacked was paying out wikipedia which offends me.\n",
      "* * * * * * * * * \n",
      "55949\n",
      "\".\n",
      "Or whatever the hell you want\"\n",
      "* * * * * * * * * \n",
      "69353\n",
      "Damn straight. Get your facts right next time.\n",
      "* * * * * * * * * \n",
      "71096\n",
      "So, you agree with me that it's stupid to let administrators unblock themselves?\n",
      "* * * * * * * * * \n",
      "79256\n",
      "I guess the old saying holds true. In the land of fools the biggest fool is king.\n",
      "* * * * * * * * * \n",
      "84096\n",
      "Do not attack users who cooperate in contributing to wiki articles. \n",
      "68.173.95.177 \n",
      "68.173.95.177\n",
      "* * * * * * * * * \n",
      "90311\n",
      "Is it correct to say that New Zealand English contains many words from Maori? There are many place and bird names from the Maori language used, but I've heard of very few everyday words from Maori being used in everyday English.\n",
      "* * * * * * * * * \n",
      "90681\n",
      "Should I have used arse then? 65.78.144.186\n",
      "* * * * * * * * * \n",
      "90845\n",
      "Oh btw I'm being sarcastic.\n",
      "* * * * * * * * * \n",
      "91838\n",
      "Mind your business\n",
      "* * * * * * * * * \n",
      "92641\n",
      "Bulleted list\n",
      " Bulleted list\n",
      " Numbered List\n",
      " Numbered List\n",
      "* * * * * * * * * \n",
      "95939\n",
      "March 2007 \n",
      " Please stop. If you continue to vandalize Wikipedia, as you did to Cunt, you will be blocked from editing.\n",
      "* * * * * * * * * \n",
      "96539\n",
      "LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL LOL\n",
      "* * * * * * * * * \n",
      "97819\n",
      "Who even are you, and why are you talking to me?\n",
      "* * * * * * * * * \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107791\n",
      "BIG BALLS \r\n",
      "\r\n",
      "BIG BALLS\r\n",
      "\r\n",
      " ive got big balls youve got big balls shes got big balls \r\n",
      "  theyve got big balls   weve got big balls  weve got big balls \r\n",
      " \r\n",
      "\r\n",
      "        ive got great balls of fire \r\n",
      "                      BY david swartz\n",
      "* * * * * * * * * \n",
      "112825\n",
      "A sockpuppet leave me alone.\n",
      "* * * * * * * * * \n",
      "113246\n",
      "\"\r\n",
      "\r\n",
      "\"\"See no reason for it - you gotta go sometime.\"\"\r\n",
      "\"\"See no reason for it - you gotta go sometime.\"\"\r\n",
      "\"\"See no reason for it - you gotta go sometime.\"\"\r\n",
      "\"\"See no reason for it - you gotta go sometime.\"\"\r\n",
      "\"\"See no reason for it - you gotta go sometime.\"\"\r\n",
      "\"\"See no reason for it - you gotta go sometime.\"\"\r\n",
      "\"\"See no reason for it - you gotta go sometime.\"\"\r\n",
      "\"\"See no reason for it - you gotta go sometime.\"\"\r\n",
      "\"\"See no reason for it - you gotta go sometime.\"\"\r\n",
      "\"\"See no reason for it - you gotta go sometime.\"\"\r\n",
      "\"\"See no reason for it - you gotta go sometime.\"\"\r\n",
      "\"\"See no reason for it - you gotta go sometime.\"\"\r\n",
      "\"\"See no reason for it - you gotta go sometime.\"\"\r\n",
      "\"\"See no reason for it - you gotta go sometime.\"\"\r\n",
      "\"\"See no reason for it - you gotta go sometime.\"\"\r\n",
      "\"\"See no reason for it - you gotta go sometime.\"\"\r\n",
      "\"\"See no reason for it - you gotta go sometime.\"\"\r\n",
      "\"\"See no reason for it - you gotta go sometime.\"\"\r\n",
      "\"\"See no reason for it - you gotta go sometime.\"\"\r\n",
      "\"\"See no reason for it - you gotta go sometime.\"\"\r\n",
      "\"\"See no reason for it - you gotta go sometime.\"\"\r\n",
      "\"\"See no reason for it - you gotta go sometime.\"\"\r\n",
      "\"\"See no reason for it - you gotta go sometime.\"\"\r\n",
      "\"\"See no reason for it - you gotta go sometime.\"\"\r\n",
      "\"\"See no reason for it - you gotta go sometime.\"\"\r\n",
      "\"\"See no reason for it - you gotta go sometime.\"\"\r\n",
      "\"\"See no reason for it - you gotta go sometime.\"\"\r\n",
      "\"\"See no reason for it - you gotta go sometime.\"\"\r\n",
      "\"\"See no reason for it - you gotta go sometime.\"\"\r\n",
      "\"\"See no reason for it - you gotta go sometime.\"\"\r\n",
      "\"\"See no reason for it - you gotta go sometime.\"\"\r\n",
      "\"\"See no reason for it - you gotta go sometime.\"\"\r\n",
      "\"\"See no reason for it - you gotta go sometime.\"\"\r\n",
      "\"\"See no reason for it - you gotta go sometime.\"\"\r\n",
      "\"\"See no reason for it - you gotta go sometime.\"\"\r\n",
      "\"\"See no reason for it - you gotta go sometime.\"\"\r\n",
      "\"\"See no reason for it - you gotta go sometime.\"\"\r\n",
      "\"\"See no reason for it - you gotta go sometime.\"\"\r\n",
      "\"\"See no reason for it - you gotta go sometime.\"\"\r\n",
      "\"\"See no reason for it - you gotta go sometime.\"\"\r\n",
      "\"\"See no reason for it - you gotta go sometime.\"\"\r\n",
      "\"\"See no reason for it - you gotta go sometime.\"\"\r\n",
      "\"\"See no reason for it - you gotta go sometime.\"\"\r\n",
      "\"\"See no reason for it - you gotta go sometime.\"\"\r\n",
      "\"\"See no reason for it - you gotta go sometime.\"\"\r\n",
      "\"\"See no reason for it - you gotta go sometime.\"\"\r\n",
      "\"\"See no reason for it - you gotta go sometime.\"\"\r\n",
      "\"\"See no reason for it - you gotta go sometime.\"\"\r\n",
      "\"\"See no reason for it - you gotta go sometime.\"\"\r\n",
      "\"\"See no reason for it - you gotta go sometime.\"\"\r\n",
      "\"\"See no reason for it - you gotta go sometime.\"\"\r\n",
      "\"\"See no reason for it - you gotta go sometime.\"\"\r\n",
      "\"\"See no reason for it - you gotta go sometime.\"\"\r\n",
      "\"\"See no reason for it - you gotta go sometime.\"\"\r\n",
      "\"\"See no reason for it - you gotta go sometime.\"\"\r\n",
      "\"\"See no reason for it - you gotta go sometime.\"\"\r\n",
      "\"\"See no reason for it - you gotta go sometime.\"\"\r\n",
      "\"\"See no reason for it - you gotta go sometime.\"\"\r\n",
      "\"\"See no reason for it - you gotta go sometime.\"\"\r\n",
      "\"\"See no reason for it - you gotta go sometime.\"\"\r\n",
      "\"\"See no reason for it - you gotta go sometime.\"\"\r\n",
      "\"\"See no reason for it - you gotta go sometime.\"\"\r\n",
      "\"\"See no reason for it - you gotta go sometime.\"\"\r\n",
      "\"\"See no reason for it - you gotta go sometime.\"\"\r\n",
      "\"\"See no reason for it - you gotta go sometime.\"\"\r\n",
      "\"\"See no reason for it - you gotta go sometime.\"\"\r\n",
      "\"\"See no reason for it - you gotta go sometime.\"\"\r\n",
      "\"\"See no reason for it - you gotta go sometime.\"\"\r\n",
      "\"\"See no reason for it - you gotta go sometime.\"\"\r\n",
      "\"\"See no reason for it - you gotta go sometime.\"\"\r\n",
      "\"\"See no reason for it - you gotta go sometime.\"\"\r\n",
      "\"\"See no reason for it - you gotta go sometime.\"\"\r\n",
      "\"\"See no reason for it - you gotta go sometime.\"\"\r\n",
      "\"\"See no reason for it - you gotta go sometime.\"\"\r\n",
      "\"\"See no reason for it - you gotta go sometime.\"\"\r\n",
      "\"\"See no reason for it - you gotta go sometime.\"\"\r\n",
      "\"\"See no reason for it - you gotta go sometime.\"\"\r\n",
      "\"\"See no reason for it - you gotta go sometime.\"\"\r\n",
      "\"\"See no reason for it - you gotta go sometime.\"\"\r\n",
      "\"\"See no reason for it - you gotta go sometime.\"\"\r\n",
      "\"\"See no reason for it - you gotta go sometime.\"\"\r\n",
      "\"\"See no reason for it - you gotta go sometime.\"\"\r\n",
      "\"\"See no reason for it - you gotta go sometime.\"\"\r\n",
      "\"\"See no reason for it - you gotta go sometime.\"\"\r\n",
      "\"\"See no reason for it - you gotta go sometime.\"\"\r\n",
      "\"\"See no reason for it - you gotta go sometime.\"\"\r\n",
      "\"\"See no reason for it - you gotta go sometime.\"\"\r\n",
      "\"\"See no reason for it - you gotta go sometime.\"\"\r\n",
      "\"\"See no reason for it - you gotta go sometime.\"\"\r\n",
      "\"\n",
      "* * * * * * * * * \n",
      "115198\n",
      "\"\r\n",
      "\r\n",
      "He's tall\r\n",
      "He was 5'7\"\" when He was human and when He was immortalHUGANTINORMOUS!!!!!!!!!!! Of course He was a baby. But He's an adult now. \"\n",
      "* * * * * * * * * \n",
      "124391\n",
      "MONKEY MONKEY MONEY MONKEY MONKEY\n",
      "* * * * * * * * * \n"
     ]
    }
   ],
   "source": [
    "# false positives\n",
    "\n",
    "print(\"Examples of false positives:\")\n",
    "\n",
    "import random, time\n",
    "\n",
    "for i in range(0, len(svm_predictions)):\n",
    "    if (svm_predictions[i] == 1):\n",
    "        if (X_raw_train.iloc[i]['any_toxic'] == 0):\n",
    "            if (random.uniform(0, 1) < 0.05): # to print only 5% of the false positives\n",
    "                print(i)\n",
    "                print(X_raw_train.iloc[i]['comment_text'])\n",
    "                print('* * * * * * * * * ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Set performance\n",
    "\n",
    "Since we are concerned with the minority class (that of positives for toxicity), optimizing precision and the true positive rate is more important that optimizing the true negative rate and accuracy (which is biased towards the majority class - negative for toxicity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 3299, 'Neg': 28616, 'TP': 2309, 'TN': 27332, 'FP': 1284, 'FN': 990, 'Accuracy': 0.928748237505875, 'Precision': 0.6426384636793766, 'Recall': 0.6999090633525311, 'desc': 'svm_test'}\n"
     ]
    }
   ],
   "source": [
    "svm_performance_test = BinaryClassificationPerformance(svm.predict(X_test), y_test, 'svm_test')\n",
    "svm_performance_test.compute_measures()\n",
    "print(svm_performance_test.performance_measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC Plot for training and test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fits = [svm_performance_train, svm_performance_test]\n",
    "\n",
    "plt.plot(fits[0].performance_measures['FP']/fits[0].performance_measures['Neg'],\n",
    "         fits[0].performance_measures['TP']/fits[0].performance_measures['Pos'], 'bo', color=\"green\")\n",
    "plt.plot(fits[1].performance_measures['FP']/fits[1].performance_measures['Neg'],\n",
    "         fits[1].performance_measures['TP']/fits[1].performance_measures['Pos'], 'bo', color=\"red\")\n",
    "\n",
    "for fit in fits:\n",
    "    plt.text(fit.performance_measures['FP'] / fit.performance_measures['Neg'], \n",
    "              fit.performance_measures['TP'] / fit.performance_measures['Pos'], fit.desc)\n",
    "plt.axis([0, 0.5, 0, 1])\n",
    "plt.title('ROC plot: training set')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SUBMSSION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic_data is: <class 'pandas.core.frame.DataFrame'>\n",
      "toxic_data has 153164 rows and 2 columns \n",
      "\n",
      "the data types for each of the columns in toxic_data:\n",
      "id              object\n",
      "comment_text    object\n",
      "dtype: object \n",
      "\n",
      "the first 10 rows in toxic_data:\n",
      "                 id                                       comment_text\n",
      "0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...\n",
      "1  0000247867823ef7  == From RfC == \\r\\n\\r\\n The title is fine as i...\n",
      "2  00013b17ad220c46  \" \\r\\n\\r\\n == Sources == \\r\\n\\r\\n * Zawe Ashto...\n",
      "3  00017563c3f7919a  :If you have a look back at the source, the in...\n",
      "4  00017695ad8997eb          I don't anonymously edit articles at all.\n",
      "Shape of HashingVectorizer X:\n",
      "(153164, 32768)\n",
      "Look at a few rows of the new quantitative features: \n",
      "   word_count  occur_fuck  punc_count  uppercase_letters\n",
      "0          72           2           0                  4\n",
      "1          13           0           0                  7\n",
      "2          16           0           0                  4\n",
      "3          38           0           0                  4\n",
      "4           7           0           0                  1\n",
      "5          16           0           0                  2\n",
      "6          31           0           0                  5\n",
      "7           6           0           0                  1\n",
      "8         109           0           0                 41\n",
      "9          41           0           0                  7\n",
      "Size of combined bag of words and new quantitative variables matrix:\n",
      "(153164, 32772)\n",
      "(153164, 32772)\n",
      "Shape of X_test for submission:\n",
      "(153164, 32772)\n",
      "SUCCESS!\n",
      "Number of rows in the submission test set (should be 153,164): \n"
     ]
    }
   ],
   "source": [
    "raw_data, X_test_submission = process_raw_data(fn='toxiccomments_test.csv', my_random_seed=80, test=True)\n",
    "print(\"Number of rows in the submission test set (should be 153,164): \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2249027186545141\n"
     ]
    }
   ],
   "source": [
    "# store the id from the raw data\n",
    "my_submission = pd.DataFrame(raw_data[\"id\"])\n",
    "# concatenate predictions to the id\n",
    "my_submission[\"prediction\"] = svm.predict(X_test_submission)\n",
    "# look at the proportion of positive predictions\n",
    "print(my_submission['prediction'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>word_count</th>\n",
       "      <th>punc_count</th>\n",
       "      <th>occur_fuck</th>\n",
       "      <th>uppercase_letters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>== From RfC == \\r\\n\\r\\n The title is fine as i...</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>\" \\r\\n\\r\\n == Sources == \\r\\n\\r\\n * Zawe Ashto...</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>:If you have a look back at the source, the in...</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>I don't anonymously edit articles at all.</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0001ea8717f6de06</td>\n",
       "      <td>Thank you for understanding. I think very high...</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>00024115d4cbde0f</td>\n",
       "      <td>Please do not add nonsense to Wikipedia. Such ...</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>000247e83dcc1211</td>\n",
       "      <td>:Dear god this site is horrible.</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00025358d4737918</td>\n",
       "      <td>\" \\r\\n Only a fool can believe in such numbers...</td>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00026d1092fe71cc</td>\n",
       "      <td>== Double Redirects == \\r\\n\\r\\n When fixing do...</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  \\\n",
       "0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...   \n",
       "1  0000247867823ef7  == From RfC == \\r\\n\\r\\n The title is fine as i...   \n",
       "2  00013b17ad220c46  \" \\r\\n\\r\\n == Sources == \\r\\n\\r\\n * Zawe Ashto...   \n",
       "3  00017563c3f7919a  :If you have a look back at the source, the in...   \n",
       "4  00017695ad8997eb          I don't anonymously edit articles at all.   \n",
       "5  0001ea8717f6de06  Thank you for understanding. I think very high...   \n",
       "6  00024115d4cbde0f  Please do not add nonsense to Wikipedia. Such ...   \n",
       "7  000247e83dcc1211                   :Dear god this site is horrible.   \n",
       "8  00025358d4737918  \" \\r\\n Only a fool can believe in such numbers...   \n",
       "9  00026d1092fe71cc  == Double Redirects == \\r\\n\\r\\n When fixing do...   \n",
       "\n",
       "   word_count  punc_count  occur_fuck  uppercase_letters  \n",
       "0          72           0           2                  4  \n",
       "1          13           0           0                  7  \n",
       "2          16           0           0                  4  \n",
       "3          38           0           0                  4  \n",
       "4           7           0           0                  1  \n",
       "5          16           0           0                  2  \n",
       "6          31           0           0                  5  \n",
       "7           6           0           0                  1  \n",
       "8         109           0           0                 41  \n",
       "9          41           0           0                  7  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0001ea8717f6de06</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>00024115d4cbde0f</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>000247e83dcc1211</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00025358d4737918</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00026d1092fe71cc</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  prediction\n",
       "0  00001cee341fdb12        True\n",
       "1  0000247867823ef7       False\n",
       "2  00013b17ad220c46        True\n",
       "3  00017563c3f7919a       False\n",
       "4  00017695ad8997eb       False\n",
       "5  0001ea8717f6de06       False\n",
       "6  00024115d4cbde0f       False\n",
       "7  000247e83dcc1211        True\n",
       "8  00025358d4737918       False\n",
       "9  00026d1092fe71cc       False"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_submission.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153164, 2)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export submission file as pdf\n",
    "# CHANGE FILE PATH: \n",
    "my_submission.to_csv('sample_submissions/2nd_Iter_toxiccomments_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
